{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import plotly.express as px\n",
    "from scipy.stats import chi2\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "prop = font_manager.FontProperties(fname=\"/home/joseph/.fonts/texgyreheroscn-regular.otf\")\n",
    "prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from needletail import parse_fastx_file, NeedletailError, reverse_complement, normalize_seq\n",
    "ASESMBLY_FASTA_FILE = \"../a9_genome_masked.fa\"\n",
    "#MIN_LENGTH = 1_000_000\n",
    "MIN_LENGTH = 0\n",
    "\n",
    "chr_lengths = {}\n",
    "\n",
    "try:\n",
    "    for record in parse_fastx_file(ASESMBLY_FASTA_FILE):\n",
    "        chr_lengths[record.id] = len(record.seq)\n",
    "except NeedletailError:\n",
    "    print(\"Invalid Fastq file\")\n",
    "\n",
    "# How many are >= MIN_LENGTH\n",
    "long_chrs = {k: v for k, v in chr_lengths.items() if v >= MIN_LENGTH}\n",
    "print(f\"Number of chromosomes >= {MIN_LENGTH:,} bp: {len(long_chrs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_chrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PL-LMM-LRT ml-reml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_df = pl.read_csv(\"/mnt/data/development/consgwas/hoiho/results_wholepop_final_glmm_plrt/gwas_results/glmm_plrt_rds_status_rds_status_results.csv\")\n",
    "northern_gwas_df = pl.read_csv(\"/mnt/data/development/consgwas/hoiho/results_northernpop_final_glmm_plrt/gwas_results/glmm_plrt_rds_status_rds_status_results.csv\")\n",
    "gv_gwas_df = pl.read_csv(\"/mnt/data/development/consgwas/hoiho/results_wholepop_final_glmm_plrt/gwas_results/glmm_plrt_gv_status_gv_status_results.csv\")\n",
    "\n",
    "# Indels\n",
    "indel_gwas_df = pl.read_csv(\"/mnt/data/development/consgwas/hoiho/results_wholepop_final_glmm_plrt_indels/gwas_results/glmm_plrt_rds_status_rds_status_results.csv\")\n",
    " \n",
    "# Imputed\n",
    "imputed_gwas_df = pl.read_csv(\"/mnt/data/development/consgwas/hoiho/results_wholepop_imputed_final_glmm_plrt/gwas_results/glmm_plrt_rds_status_rds_status_results.csv\")\n",
    "\n",
    "# gwas_df = pl.read_csv(\"/mnt/data/development/consgwas/hoiho/results_wholepop_final_glmm_plrt/gwas_results/glmm_plrt_gv_status_gv_status_results.csv\")\n",
    "# northern_gwas_df = pl.read_csv(\"/mnt/data/development/consgwas/hoiho/results_northernpop_final_glmm_plrt/gwas_results/glmm_plrt_gv_status_gv_status_results.csv\")\n",
    "\n",
    "# glmm_plrt_ds_status_ds_status_results.csv\n",
    "# gwas_df = pl.read_csv(\"/mnt/data/development/consgwas/hoiho/results_wholepop_final_glmm_plrt/gwas_results/glmm_plrt_ds_status_ds_status_results.csv\")\n",
    "# northern_gwas_df = pl.read_csv(\"/mnt/data/development/consgwas/hoiho/results_northernpop_final_glmm_plrt/gwas_results/glmm_plrt_ds_status_ds_status_results.csv\")\n",
    "\n",
    "gwas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def process_gwas_for_qq(df):\n",
    "    \"\"\"\n",
    "    Processes a GWAS dataframe to get values for a QQ plot and calculates lambda GC.\n",
    "    \n",
    "    Args:\n",
    "        df: A dataframe with a 'P' column containing p-values.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - expected_log: -log10 transformed expected p-values\n",
    "        - observed_log: -log10 transformed observed p-values\n",
    "        - lambda_gc: The genomic inflation factor (lambda GC)\n",
    "    \"\"\"\n",
    "    # Extract p-values and remove any NaNs\n",
    "    pvals = df[\"P\"].to_numpy()\n",
    "    pvals = pvals[~np.isnan(pvals)]\n",
    "\n",
    "    # --- Calculate Lambda GC ---\n",
    "    # Convert p-values to chi-squared statistics\n",
    "    chisq = chi2.isf(pvals, df=1)\n",
    "    # Calculate lambda GC as the ratio of the median of observed vs expected chi-squared stats\n",
    "    lambda_gc = np.median(chisq) / chi2.ppf(0.5, 1) # chi2.ppf(0.5, 1) is approx 0.4549\n",
    "\n",
    "    # --- Prepare p-values for QQ plot ---\n",
    "    pvals = np.sort(pvals)\n",
    "    n = len(pvals)\n",
    "    \n",
    "    # Calculate expected p-values under the null hypothesis\n",
    "    expected = np.linspace(1 / (n + 1), n / (n + 1), n)\n",
    "\n",
    "    # Apply -log10 transformation\n",
    "    expected_log = -np.log10(expected)\n",
    "    observed_log = -np.log10(pvals)\n",
    "    \n",
    "    return expected_log, observed_log, lambda_gc\n",
    "\n",
    "# Process both of your GWAS result dataframes\n",
    "expected1, observed1, lambda1 = process_gwas_for_qq(gwas_df)\n",
    "expected2, observed2, lambda2 = process_gwas_for_qq(northern_gwas_df)\n",
    "\n",
    "# Imputed\n",
    "expected3, observed3, lambda3 = process_gwas_for_qq(imputed_gwas_df)\n",
    "\n",
    "# Indel\n",
    "expected4, observed4, lambda4 = process_gwas_for_qq(indel_gwas_df)\n",
    "\n",
    "# GV Status\n",
    "expected5, observed5, lambda5 = process_gwas_for_qq(gv_gwas_df)\n",
    "\n",
    "# --- Create the Plot ---\n",
    "plt.figure(figsize=(8, 8)) # A square figure is best for QQ plots\n",
    "\n",
    "# Scatter plot for the first GWAS (Whole population)\n",
    "plt.scatter(expected1, observed1, color='#CABEE9', alpha=0.7, s=12, label='Whole Population')\n",
    "\n",
    "# Scatter plot for the second GWAS (Northern population)\n",
    "# plt.scatter(expected2, observed2, color='#7C7189', alpha=0.7, s=12, label='Northern Population')\n",
    "\n",
    "# Scatter plot for the imputed GWAS\n",
    "# plt.scatter(expected3, observed3, color='#FF6F91', alpha=0.7, s=12, label='Imputed Variants')\n",
    "\n",
    "# Scatter plot for the indel GWAS\n",
    "# plt.scatter(expected4, observed4, color='#1982C4', alpha=0.7, s=12, label='Indels')\n",
    "\n",
    "# Scatter plot for the GV status GWAS\n",
    "plt.scatter(expected5, observed5, color='#F6D55C', alpha=0.7, s=12, label='GV Status')\n",
    "\n",
    "# Determine the maximum value to make the plot square and the line corner-to-corner\n",
    "max_val = max(np.max(expected1), np.max(observed1), np.max(expected2), np.max(observed2), np.max(expected3), np.max(observed3), np.max(expected4), np.max(observed4))\n",
    "plot_limit = np.ceil(max_val) # Round up to the nearest integer for a clean axis\n",
    "\n",
    "# Plot the y=x line\n",
    "plt.plot([0, plot_limit], [0, plot_limit], color='#FAE093', linestyle='--', lw=2, label='y=x')\n",
    "\n",
    "# Set axis limits to be equal, ensuring a square plot\n",
    "plt.xlim(0, plot_limit)\n",
    "plt.ylim(0, plot_limit)\n",
    "\n",
    "\n",
    "# Add labels and the title with Lambda GC values\n",
    "plt.xlabel('-log10(Expected p-value)', fontsize=12)\n",
    "plt.ylabel('-log10(Observed p-value)', fontsize=12)\n",
    "plt.title(\n",
    "    f'QQ Plot of RDS Status GWAS p-values\\n'\n",
    "    # f'λGC (Whole Pop) = {lambda1:.3f}  |  λGC (Northern Pop) = {lambda2:.3f} |  λGC (Imputed) = {lambda3:.3f} | λGC (Indels) = {lambda4:.3f}',\n",
    "    f'λGC (Whole Pop) = {lambda1:.3f}  |  λGC (GV Status) = {lambda5:.3f}',\n",
    "    fontsize=14\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add -log10p and then sort by it\n",
    "# Remove -log10p nulls\n",
    "gwas_df = gwas_df.with_columns(\n",
    "    (-pl.col(\"P\").log10()).alias(\"-log10p\")\n",
    ")\n",
    "gwas_df = gwas_df.filter(pl.col(\"-log10p\").is_not_null())\n",
    "gwas_df = gwas_df.sort(\"-log10p\", descending=True)\n",
    "#gwas_df.head()\n",
    "\n",
    "# Same for northern\n",
    "northern_gwas_gwas = northern_gwas_df.with_columns(\n",
    "    (-pl.col(\"P\").log10()).alias(\"-log10p\")\n",
    ")\n",
    "northern_gwas_gwas = northern_gwas_gwas.filter(pl.col(\"-log10p\").is_not_null())\n",
    "northern_gwas_gwas = northern_gwas_gwas.sort(\"-log10p\", descending=True)\n",
    "#northern_gwas_gwas.head()\n",
    "\n",
    "# Same for indels and imputed\n",
    "indel_gwas_gwas = indel_gwas_df.with_columns(\n",
    "    (-pl.col(\"P\").log10()).alias(\"-log10p\")\n",
    ")\n",
    "indel_gwas_gwas = indel_gwas_gwas.filter(pl.col(\"-log10p\").is_not_null())\n",
    "indel_gwas_gwas = indel_gwas_gwas.sort(\"-log10p\", descending=True)\n",
    "#indel_gwas_gwas.head()\n",
    "\n",
    "imputed_gwas_gwas = imputed_gwas_df.with_columns(\n",
    "    (-pl.col(\"P\").log10()).alias(\"-log10p\")\n",
    ")\n",
    "imputed_gwas_gwas = imputed_gwas_gwas.filter(pl.col(\"-log10p\").is_not_null())\n",
    "imputed_gwas_gwas = imputed_gwas_gwas.sort(\"-log10p\", descending=True)\n",
    "#imputed_gwas_gwas.head()\n",
    "\n",
    "gv_gwas_df = gv_gwas_df.with_columns(\n",
    "    (-pl.col(\"P\").log10()).alias(\"-log10p\")\n",
    ")\n",
    "gv_gwas_df = gv_gwas_df.filter(pl.col(\"-log10p\").is_not_null())\n",
    "gv_gwas_df = gv_gwas_df.sort(\"-log10p\", descending=True)\n",
    "gv_gwas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_gwas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_gwas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do an intersect join on marker, keeping only the -log10p columns from each dataframe\n",
    "merged_df = gwas_df.join(\n",
    "    gv_gwas_df.select([\"Marker\", \"-log10p\"]),\n",
    "    on=\"Marker\",\n",
    "    how=\"inner\",\n",
    "    suffix=\"_gv\"\n",
    ")\n",
    "# Keep only the marker and -log10p columns (-log10p, and -log10p_gv)\n",
    "merged_df = merged_df.select([\"Marker\", \"-log10p\", \"-log10p_gv\"])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between the two\n",
    "\n",
    "# Only look at the top 5%\n",
    "\n",
    "# Drop everything below 'baseline' of -log10p of 2.0 in either dataset\n",
    "threshold = 0.5\n",
    "merged_df_filtered = merged_df.filter(\n",
    "    (pl.col(\"-log10p\") >= threshold) | (pl.col(\"-log10p_gv\") >= threshold)\n",
    ")\n",
    "\n",
    "px.scatter(\n",
    "    merged_df_filtered.to_pandas(),\n",
    "    x=\"-log10p\",\n",
    "    y=merged_df_filtered[\"-log10p_gv\"].to_numpy(),\n",
    "    trendline=\"ols\",\n",
    "    labels={\n",
    "        \"-log10p\": \"-log10 p-value (RDS Status GWAS)\",\n",
    "        \"y\": \"-log10 p-value (GV Status GWAS)\"\n",
    "    },\n",
    "    title=\"Correlation of -log10 p-values between RDS Status GWAS and GV Status GWAS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.corrcoef (for r^2)\n",
    "np.corrcoef(merged_df_filtered[\"-log10p\"].to_numpy(), merged_df_filtered[\"-log10p_gv\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_chrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# =============================================================================\n",
    "# Matplotlib Drop-in Replacement Cell\n",
    "#\n",
    "# This cell assumes the following variables already exist in your environment:\n",
    "#   - gwas_df:      A polars DataFrame with GWAS results for the first plot.\n",
    "#   - gv_gwas_df:   A polars DataFrame with GWAS results for the second plot.\n",
    "#   - long_chrs:    A Python dictionary mapping chromosome/contig names to their lengths.\n",
    "# =============================================================================\n",
    "\n",
    "# --- Font and Plotting Style Configuration ---\n",
    "try:\n",
    "    mpl.rcParams['font.family'] = 'sans-serif'\n",
    "    mpl.rcParams['font.sans-serif'] = ['Tex Gyre Heros', 'Helvetica', 'Arial']\n",
    "    mpl.rcParams['axes.spines.top'] = False\n",
    "    mpl.rcParams['axes.spines.right'] = False\n",
    "    mpl.rcParams['xtick.major.size'] = 7\n",
    "    mpl.rcParams['ytick.major.size'] = 7\n",
    "    mpl.rcParams['xtick.labelsize'] = 12\n",
    "    mpl.rcParams['ytick.labelsize'] = 12\n",
    "except Exception as e:\n",
    "    print(f\"Could not set Tex Gyre Heros font. Using default sans-serif. Error: {e}\")\n",
    "\n",
    "# --- Configuration (Matching Original Plotly Setup) ---\n",
    "P_VALUE_CUTOFF = 0.0\n",
    "MARKER_SIZE = 6\n",
    "GAP_FACTOR = 0.05\n",
    "LABEL_EVERY_NTH_CHR = 3\n",
    "NUM_CHROMS_TO_LABEL = 30\n",
    "\n",
    "# --- Data Preparation Function (pandas equivalent of your polars function) ---\n",
    "def prepare_manhattan_data_pandas(df_pandas, chr_lengths_dict):\n",
    "    \"\"\"\n",
    "    Prepares a pandas DataFrame for Manhattan plotting, mirroring the original polars logic.\n",
    "    \"\"\"\n",
    "    df = df_pandas.copy()\n",
    "    # Calculate -log10(p) and apply cutoff\n",
    "    df['-log10p'] = -np.log10(df['P'])\n",
    "    df = df[df['-log10p'] >= P_VALUE_CUTOFF]\n",
    "\n",
    "    # Sort chromosomes by length (descending) to establish the plotting order\n",
    "    sorted_chroms_by_length = sorted(chr_lengths_dict, key=chr_lengths_dict.get, reverse=True)\n",
    "    \n",
    "    # Filter the sort order to only include chromosomes present in the data\n",
    "    present_chroms = df['Chr'].unique()\n",
    "    sorted_chroms_present = [c for c in sorted_chroms_by_length if c in present_chroms]\n",
    "    \n",
    "    # Apply the categorical ordering and sort the DataFrame\n",
    "    df['Chr'] = pd.Categorical(df['Chr'], categories=sorted_chroms_present, ordered=True)\n",
    "    df = df.sort_values(['Chr', 'Pos'])\n",
    "\n",
    "    # Calculate the cumulative offset for each chromosome\n",
    "    mean_length = np.mean(list(chr_lengths_dict.values()))\n",
    "    gap_size = int(mean_length * GAP_FACTOR)\n",
    "    \n",
    "    offsets, current_offset, ticks_data = {}, 0, []\n",
    "    for i, chrom in enumerate(sorted_chroms_present):\n",
    "        offsets[chrom] = current_offset\n",
    "        chrom_length = chr_lengths_dict.get(chrom, 0)\n",
    "        ticks_data.append({\n",
    "            'Chr': chrom, 'Chr_order': i,\n",
    "            'tick_pos': current_offset + chrom_length / 2,\n",
    "            'offset': current_offset, 'length': chrom_length\n",
    "        })\n",
    "        current_offset += chrom_length + gap_size\n",
    "\n",
    "    # Apply the offset to create the final x-coordinate for plotting\n",
    "    df['offset'] = df['Chr'].map(offsets).astype(np.int64)\n",
    "    df['x'] = df['Pos'].astype(np.int64) + df['offset']\n",
    "    \n",
    "    ticks_df = pd.DataFrame(ticks_data)\n",
    "    return df, ticks_df\n",
    "\n",
    "# --- Data Conversion and Preparation ---\n",
    "# 1. Convert your existing polars DataFrames to pandas DataFrames\n",
    "gwas_df_pd = gwas_df.to_pandas()\n",
    "gv_gwas_df_pd = gv_gwas_df.to_pandas()\n",
    "\n",
    "# 2. Prepare each pandas DataFrame for plotting\n",
    "plot_df_whole, ticks_df = prepare_manhattan_data_pandas(gwas_df_pd, long_chrs)\n",
    "plot_df_gv, _ = prepare_manhattan_data_pandas(gv_gwas_df_pd, long_chrs)\n",
    "\n",
    "\n",
    "# --- Plotting with Matplotlib ---\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 9), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.1)\n",
    "\n",
    "# Define colors to match the original plot\n",
    "colors = [\"#7C7189\", \"#BC8E7D\"] # Purple-grey, Brown\n",
    "\n",
    "# Loop through the chromosomes in their length-sorted order and plot\n",
    "for i, row in ticks_df.iterrows():\n",
    "    chrom, color = row['Chr'], colors[i % len(colors)]\n",
    "    \n",
    "    # Plot for the top panel (RDS Status)\n",
    "    df_subset_whole = plot_df_whole[plot_df_whole['Chr'] == chrom]\n",
    "    if not df_subset_whole.empty:\n",
    "        ax1.scatter(df_subset_whole['x'], df_subset_whole['-log10p'], color=color, s=MARKER_SIZE, alpha=0.8, rasterized=True)\n",
    "\n",
    "    # Plot for the bottom panel (GV Status)\n",
    "    df_subset_gv = plot_df_gv[plot_df_gv['Chr'] == chrom]\n",
    "    if not df_subset_gv.empty:\n",
    "        ax2.scatter(df_subset_gv['x'], df_subset_gv['-log10p'], color=color, s=MARKER_SIZE, alpha=0.8, rasterized=True)\n",
    "\n",
    "\n",
    "# --- Customize Layout and Axes (Replicating Original Logic) ---\n",
    "# Select which chromosome ticks to display\n",
    "candidate_labels_df = ticks_df[ticks_df['Chr_order'] < NUM_CHROMS_TO_LABEL]\n",
    "labels_df = candidate_labels_df[\n",
    "    (candidate_labels_df['Chr_order'] == 0) | \n",
    "    ((candidate_labels_df['Chr_order'] + 1) % LABEL_EVERY_NTH_CHR == 0)\n",
    "]\n",
    "scaffolds_df = ticks_df[ticks_df['Chr_order'] >= NUM_CHROMS_TO_LABEL]\n",
    "\n",
    "tick_vals = labels_df['tick_pos'].tolist()\n",
    "tick_texts = labels_df['Chr'].tolist()\n",
    "\n",
    "# Group remaining contigs into an \"Other\" category\n",
    "if not scaffolds_df.empty:\n",
    "    scaffold_tick_pos = (scaffolds_df['offset'].min() + scaffolds_df['offset'].max() + scaffolds_df['length'].iloc[-1]) / 2\n",
    "    tick_vals.append(scaffold_tick_pos)\n",
    "    tick_texts.append(\"Other\")\n",
    "\n",
    "# Set all axis labels, ticks, and limits\n",
    "ax2.set_xlabel(\"Genomic Position\", fontsize=16)\n",
    "ax2.set_xticks(tick_vals)\n",
    "ax2.set_xticklabels(tick_texts, rotation=45, ha='right')\n",
    "ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "# Set fixed Y-axis to match the target image\n",
    "shared_max_y, min_y = 10.5, -0.5\n",
    "\n",
    "ax1.set_ylabel(\"-log10(p) [RDS Status]\", fontsize=14)\n",
    "ax1.set_ylim(min_y, shared_max_y)\n",
    "ax1.grid(axis='y', color='#e0e0e0', linestyle='-')\n",
    "\n",
    "ax2.set_ylabel(\"-log10(p) [GV Status]\", fontsize=14)\n",
    "ax2.set_ylim(min_y, shared_max_y)\n",
    "ax2.grid(axis='y', color='#e0e0e0', linestyle='-')\n",
    "\n",
    "# Add panel labels (\"a\", \"b\") without parentheses\n",
    "ax1.text(0.02, 0.9, \"a\", transform=ax1.transAxes, fontsize=24, fontweight='bold', va='top')\n",
    "ax2.text(0.02, 0.9, \"b\", transform=ax2.transAxes, fontsize=24, fontweight='bold', va='top')\n",
    "\n",
    "# --- Save and Display the Figure ---\n",
    "# You can uncomment the desired save format\n",
    "plt.savefig(\"manhattan_matplotlib_output.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(\"manhattan_matplotlib_output.svg\", bbox_inches='tight', format='svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Configuration ---\n",
    "P_VALUE_CUTOFF = 0.0\n",
    "MARKER_SIZE = 3\n",
    "GAP_FACTOR = 0.05\n",
    "LABEL_EVERY_NTH_CHR = 3 # Label every 3rd chromosome to prevent overlap\n",
    "\n",
    "# --- Dummy Data (assuming your real data is loaded) ---\n",
    "# long_chrs = ...\n",
    "# gwas_df = ...\n",
    "# gv_gwas_df = ...\n",
    "\n",
    "# --- Data Preparation Function (Corrected and Final) ---\n",
    "def prepare_manhattan_data(df, chr_lengths_dict, p_cutoff=0, gap_factor=0.05):\n",
    "    sorted_chroms_by_length = sorted(chr_lengths_dict, key=chr_lengths_dict.get, reverse=True)\n",
    "    chrom_order_map = {chrom: i for i, chrom in enumerate(sorted_chroms_by_length)}\n",
    "    plot_df = df.clone().with_columns(\n",
    "        (-pl.col(\"P\").log10()).alias(\"-log10p\")\n",
    "    ).filter(\n",
    "        pl.col(\"-log10p\") >= p_cutoff\n",
    "    ).with_columns([\n",
    "        pl.col(\"Chr\").str.extract(r\"(\\d+)\", 1).cast(pl.Int64).fill_null(999).alias(\"Chr_label\"),\n",
    "        pl.col(\"Chr\").replace(chrom_order_map).cast(pl.Int64).alias(\"Chr_order\")\n",
    "    ]).sort(\"Chr_order\", \"Pos\")\n",
    "    sorted_chroms_present = plot_df.select(\"Chr\", \"Chr_order\").unique().sort(\"Chr_order\")[\"Chr\"].to_list()\n",
    "    chrom_lengths_sorted = [chr_lengths_dict.get(c, 0) for c in sorted_chroms_present]\n",
    "    offsets_df = pl.DataFrame({\n",
    "        \"Chr\": sorted_chroms_present, \"length\": chrom_lengths_sorted\n",
    "    }).with_columns(\n",
    "        (pl.col(\"length\").mean() * gap_factor).cast(pl.Int64).alias(\"gap\")\n",
    "    ).with_columns(\n",
    "        (pl.col(\"length\") + pl.col(\"gap\")).cum_sum().shift(1).fill_null(0).alias(\"offset\")\n",
    "    )\n",
    "    plot_df = plot_df.join(\n",
    "        offsets_df.select(\"Chr\", \"offset\"), \"Chr\", how=\"left\"\n",
    "    ).with_columns(\n",
    "        (pl.col(\"Pos\") + pl.col(\"offset\")).alias(\"x\")\n",
    "    )\n",
    "    ticks_df = offsets_df.join(\n",
    "        plot_df.group_by(\"Chr\").agg(pl.col(\"Chr_label\").first(), pl.col(\"Chr_order\").first()), \"Chr\"\n",
    "    ).with_columns(\n",
    "        (pl.col(\"offset\") + pl.col(\"length\") / 2).alias(\"tick_pos\")\n",
    "    ).sort(\"Chr_order\")\n",
    "    return plot_df, ticks_df\n",
    "\n",
    "# --- Prepare data for both populations ---\n",
    "plot_df_whole, ticks_df = prepare_manhattan_data(gwas_df, long_chrs, P_VALUE_CUTOFF, gap_factor=GAP_FACTOR)\n",
    "plot_df_gv, _ = prepare_manhattan_data(gv_gwas_df, long_chrs, P_VALUE_CUTOFF, gap_factor=GAP_FACTOR)\n",
    "\n",
    "# --- Plotting ---\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.05, row_heights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "#  # c(\"#CABEE9\", \"#7C7189\", \"#FAE093\", \"#D04E59\", \"#BC8E7D\", \"#2F3D70\")\n",
    "our_colors = [\"#CABEE9\", \"#7C7189\", \"#FAE093\", \"#D04E59\", \"#BC8E7D\", \"#2F3D70\"]\n",
    "colors = [our_colors[1], our_colors[4]]\n",
    "for i, chrom_row in enumerate(ticks_df.iter_rows(named=True)):\n",
    "    chrom = chrom_row['Chr']\n",
    "    color = colors[i % len(colors)]\n",
    "    df_subset_whole = plot_df_whole.filter(pl.col(\"Chr\") == chrom)\n",
    "    if not df_subset_whole.is_empty():\n",
    "        fig.add_trace(go.Scatter(x=df_subset_whole[\"x\"], y=df_subset_whole[\"-log10p\"], mode='markers', marker=dict(color=color, size=MARKER_SIZE), name=chrom, hovertext=df_subset_whole[\"Marker\"], showlegend=False), row=1, col=1)\n",
    "    df_subset_northern = plot_df_gv.filter(pl.col(\"Chr\") == chrom)\n",
    "    if not df_subset_northern.is_empty():\n",
    "        fig.add_trace(go.Scatter(x=df_subset_northern[\"x\"], y=df_subset_northern[\"-log10p\"], mode='markers', marker=dict(color=color, size=MARKER_SIZE), name=chrom, hovertext=df_subset_northern[\"Marker\"], showlegend=False), row=2, col=1)\n",
    "        \n",
    "# --- Customize Layout and Axes ---\n",
    "NUM_CHROMS_TO_LABEL = 30\n",
    "candidate_labels_df = ticks_df.filter(pl.col(\"Chr_order\") < NUM_CHROMS_TO_LABEL)\n",
    "labels_df = candidate_labels_df.filter(\n",
    "    (pl.col(\"Chr_order\") == 0) | ((pl.col(\"Chr_order\") + 1) % LABEL_EVERY_NTH_CHR == 0)\n",
    ")\n",
    "scaffolds_df = ticks_df.filter(pl.col(\"Chr_order\") >= NUM_CHROMS_TO_LABEL)\n",
    "tick_vals = labels_df[\"tick_pos\"].to_list()\n",
    "tick_texts = (labels_df[\"Chr_order\"] + 1).to_list()\n",
    "if not scaffolds_df.is_empty():\n",
    "    scaffold_tick_pos = (scaffolds_df[\"tick_pos\"].min() + scaffolds_df[\"tick_pos\"].max()) / 2\n",
    "    tick_vals.append(scaffold_tick_pos)\n",
    "    tick_texts.append(\"Other\")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Genomic Position\",\n",
    "    tickvals=tick_vals, ticktext=tick_texts, tickangle=45, row=2, col=1\n",
    ")\n",
    "\n",
    "max_y_whole = plot_df_whole[\"-log10p\"].max() + 0.5\n",
    "max_y_gv = plot_df_gv[\"-log10p\"].max() + 0.5\n",
    "min_y = P_VALUE_CUTOFF - 0.5\n",
    "\n",
    "max_y_gv = max(max_y_whole, max_y_gv)\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title_text=\"-log10(p) [RDS Status]\", showgrid=True, gridwidth=1, gridcolor='#f0f0f0', \n",
    "    row=1, col=1, range=[min_y, max_y_whole]\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text=\"-log10(p) [GV Status]\", showgrid=True, gridwidth=1, gridcolor='#f0f0f0', \n",
    "    row=2, col=1, range=[min_y, max_y_gv]\n",
    ")\n",
    "fig.update_xaxes(showgrid=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    #title_text=\"Stacked Manhattan Plots for Respiratory Disease Syndrome and Gyrovirus Presence\", height=800, template=\"plotly_white\",\n",
    "    #title_font_size=20, xaxis_title_font_size=16, yaxis_title_font_size=14,\n",
    "    # Disable title\n",
    "    title_text=\"\", height=600, template=\"plotly_white\",\n",
    "    margin=dict(l=50, r=30, t=90, b=80),\n",
    "    font=dict(\n",
    "        family=\"Helvetica, Arial, sans-serif\",\n",
    "        size=12,  # Sets a base font size for elements like tick labels\n",
    "        color=\"black\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "#fig.show()\n",
    "# Save the figure with high resolution (300dpi, width=1200px, height=800px)\n",
    "fig.write_image(\"manhattan_rds_status_gv_status.png\", scale=3, width=720, height=480)\n",
    "#fig.write_image(\"manhattan_rds_status_gv_status.svg\", scale=3, width=1200, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"manhattan_rds_status_gv_status.svg\", scale=3, width=1200, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gff_eggnog_util import *\n",
    "\n",
    "GFF_PATH = \"/mnt/data/development/hoiho_working/galba/galba.converted.gff3\"\n",
    "EGGNOG_PATH = \"/mnt/data/development/hoiho_working/galba/a9.emapper.annotations\"\n",
    "\n",
    "# Initialize\n",
    "GFF_IDX = init_gff_index(GFF_PATH, feature_types=(\"gene\",\"mRNA\"))\n",
    "EGG_MAP, EGG_ALIAS = init_eggnog_map(EGGNOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the top 1.5% of SNPs, look for genes within 2kbp of them\n",
    "#top_snps = gwas_df.filter(pl.col(\"-log10p\") >= gwas_df.select(pl.col(\"-log10p\").quantile(0.9995)).item())\n",
    "# Let's do -log10(p) >= 6.0 instead\n",
    "\n",
    "# RDS\n",
    "#top_snps = gwas_df.filter(pl.col(\"-log10p\") >= 5.0) # 4 for indels, 5 for SNPs\n",
    "\n",
    "# GV \n",
    "top_snps = gv_gwas_df.filter(pl.col(\"-log10p\") >= 5.0) # 4 for indels, 5 for SNPs\n",
    "\n",
    "\n",
    "print(f\"Number of top SNPs {top_snps.height / gwas_df.height * 100:.6f}%: {top_snps.height}\")\n",
    "# What is the -log10(p) cutoff for this?\n",
    "log10p_cutoff = top_snps.select(pl.col(\"-log10p\").min()).item()\n",
    "print(f\"-log10(p) cutoff for top 1.5% SNPs: {log10p_cutoff:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the hits (1, 2, 3, ordinal) and add that as a column, so whichever it is nearby grabs\n",
    "top_snps = top_snps.with_columns(\n",
    "    pl.arange(1, top_snps.height + 1).alias(\"Rank\")\n",
    ")\n",
    "\n",
    "for i, row in enumerate(top_snps.iter_rows(named = True)):\n",
    "    chrom = row[\"Chr\"]\n",
    "    pos = row[\"Pos\"]\n",
    "    pval = row[\"P\"]\n",
    "    log10p = row[\"-log10p\"]\n",
    "    rank = row[\"Rank\"]\n",
    "    marker = row[\"Marker\"]\n",
    "    \n",
    "    # Get genes within 2kbp\n",
    "    # df = query_region(row['Chromosome'], row['Start_bp'], row['End_bp'], feature_types=(\"mRNA\",), how=\"overlap\")\n",
    "\n",
    "    nearby_genes = query_region(chrom, pos - 20000, pos + 20000, feature_types=(\"gene\", \"mRNA\"), how=\"overlap\")\n",
    "    \n",
    "    if nearby_genes.shape[0] == 0:\n",
    "        # Print out chrom, pos, log10p, and the rest leave blank\n",
    "        print(f\"{chrom}\\t{pos}\\t{rank}\\t{log10p}\\tN/A\\tN/A\\tN/A\\tN/A\")\n",
    "        continue\n",
    "    \n",
    "    # print(f\"SNP {marker} at {chrom}:{pos} (p={pval:.3e}, -log10p={log10p:.3f}) has {len(nearby_genes)} nearby genes:\")\n",
    "    nearby_genes = pl.from_pandas(nearby_genes)\n",
    "    for row in nearby_genes.iter_rows(named=True):\n",
    "        # Columns: contig\tstart\tend\tstrand\ttype\tid\tquery_key\tpreferred_name\tdescription\tgo_terms\n",
    "        gene_id = row[\"id\"]\n",
    "\n",
    "        # Only keep the primary transcript\n",
    "        if not gene_id.endswith(\".t1\"):\n",
    "            continue\n",
    "\n",
    "        # preferred name, description, go_terms\n",
    "        preferred_name = row[\"preferred_name\"] if row[\"preferred_name\"] is not None else \"N/A\"\n",
    "        description = row[\"description\"] if row[\"description\"] is not None else \"N/A\"\n",
    "        go_terms = row[\"go_terms\"] if row[\"go_terms\"] is not None else \"N/A\"\n",
    "        # Format to paste into spreadsheet as supplemental table\n",
    "        # Chr, Pos, -log10(p), Gene ID, Preferred Name, Description, GO Terms \n",
    "        print(f\"{chrom}\\t{pos}\\t{rank}\\t{log10p}\\t{gene_id}\\t{preferred_name}\\t{description}\\t{go_terms}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top 1.5% of SNPs by -log10p\n",
    "top_percent_threshold = gwas_df.height * 0.015\n",
    "top_snps_df = gwas_df.head(int(top_percent_threshold))\n",
    "# Print shape\n",
    "print(\"Top SNPs DF shape:\", top_snps_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergence_indiv_pops = pl.read_csv(\"../ARG/tsinfer/divergent_regions_summary_indiv_pops.csv\")\n",
    "divergence_grouped_pops = pl.read_csv(\"../ARG/tsinfer/divergent_regions_summary_grouped_pops.csv\")\n",
    "#divergence_indiv_pops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyranges as pr\n",
    "divergence_pr = pr.PyRanges(divergence_indiv_pops.rename({\"Start_bp\": \"Start\", \"End_bp\": \"End\"}).to_pandas())\n",
    "divergence_grouped_pr = pr.PyRanges(divergence_grouped_pops.rename({\"Start_bp\": \"Start\", \"End_bp\": \"End\"}).to_pandas())\n",
    "top_snps_pr = pr.PyRanges(top_snps_df.rename({\"Chr\": \"Chromosome\", \"Pos\": \"Start\"}).with_columns((pl.col(\"Start\") + 1).alias(\"End\")).to_pandas())\n",
    "overlaps = divergence_pr.join(top_snps_pr)\n",
    "overlaps_df = pl.from_pandas(overlaps.df)\n",
    "overlaps_grouped = divergence_grouped_pr.join(top_snps_pr)\n",
    "overlaps_grouped_df = pl.from_pandas(overlaps_grouped.df)\n",
    "overlaps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps_grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Older code (but still to be used!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot a qq plot of orig_df and northern_pop_only_df\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "# Create a new figure\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "colors = [\"red\", \"blue\", \"orange\", \"yellow\"]\n",
    "y_max = 0.0\n",
    "\n",
    "for i, qq_df in enumerate([orig_df, gwas_df]):\n",
    "    # Create a QQ plot\n",
    "    # Calculate the expected p-values\n",
    "    \n",
    "    # Calculate the observed p-values\n",
    "    observed_pvals = np.sort(qq_df[\"p\"].to_numpy())\n",
    "    # Remove NaN's\n",
    "    observed_pvals = observed_pvals[~np.isnan(observed_pvals)]\n",
    "    observed_pvals = np.sort(observed_pvals)\n",
    "\n",
    "    n = len(observed_pvals)\n",
    "    expected_pvals = np.linspace(0, 1, n+1)\n",
    "    # Calculate the -log10 of the expected and observed p-values\n",
    "    expected_neg_log10_pvals = -np.log10(expected_pvals[1:])\n",
    "    observed_neg_log10_pvals = -np.log10(observed_pvals[0:])\n",
    "    y_max = max(y_max, observed_neg_log10_pvals.max())\n",
    "\n",
    "    # Create a scatter plot\n",
    "    ax.scatter(\n",
    "        expected_neg_log10_pvals,\n",
    "        observed_neg_log10_pvals,\n",
    "        alpha=0.5,\n",
    "        color=colors[i]\n",
    "    )\n",
    "\n",
    "# Add a diagonal line\n",
    "x = np.linspace(0, max(expected_neg_log10_pvals), 100)\n",
    "y = x\n",
    "ax.plot(\n",
    "    x,\n",
    "    y,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"y=x\",\n",
    "\n",
    ")\n",
    "\n",
    "# Add a legend\n",
    "#ax.legend()\n",
    "# Add labels\n",
    "ax.set_xlabel(\"-log10(Expected p-value)\")\n",
    "ax.set_ylabel(\"-log10(Observed p-value)\")\n",
    "# Add a title\n",
    "ax.set_title(\"QQ Plot of GWAS p-values\")\n",
    "\n",
    "print(y_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = np.array(np.sort(gwas_df[\"p\"].to_numpy()))\n",
    "# Remove NaNs\n",
    "pvals = pvals[~np.isnan(pvals)]\n",
    "chisq = chi2.isf(pvals, df=1)\n",
    "lambda_gc = np.median(chisq) / 0.456\n",
    "print(\"λGC:\", lambda_gc)\n",
    "\n",
    "pvals = np.array(np.sort(orig_df[\"p\"].to_numpy()))\n",
    "# Remove NaNs\n",
    "pvals = pvals[~np.isnan(pvals)]\n",
    "chisq = chi2.isf(pvals, df=1)\n",
    "lambda_gc = np.median(chisq) / 0.456\n",
    "print(\"λGC:\", lambda_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter NaN values for p value\n",
    "orig_pdf = orig_df.to_pandas()\n",
    "orig_pdf = orig_pdf[~orig_pdf[\"p\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
