{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "from cyvcf2 import VCF\n",
    "import random\n",
    "import plotly.express as px\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"plotly_mimetype+notebook_connected\"\n",
    "\n",
    "# Load up metadata from \"DNA from hoiho genomesv2.csv\"\n",
    "metadata = pl.read_csv(\n",
    "    \"Hoiho_Genomes_24Feb2024_JGG_3Pops.csv\", separator=\"\\t\"\n",
    ")\n",
    "\n",
    "metadata = metadata.with_columns(\n",
    "    pl.col(\"ID\").replace(\"P29 \", \"P29\").alias(\"ID\")\n",
    ")\n",
    "\n",
    "# Next is C101/CE9\n",
    "metadata = metadata.with_columns(\n",
    "    pl.col(\"ID\").replace(\"C101/CE9\", \"CE9\").alias(\"ID\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples found in bcf file using cyvcf2\n",
    "\n",
    "bcf_file = \"merged.a9.filtered.qual99.maf0.05.biallelic.bcf\"\n",
    "\n",
    "vcf = VCF(bcf_file)\n",
    "\n",
    "samples = vcf.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only samples in the metadata that are also in the bcf file\n",
    "pop_filtered = metadata.filter(pl.col(\"ID\").is_in(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of each Population from the Population3 field\n",
    "pop_counts = pop_filtered.group_by(\"Population3\").len()\n",
    "pop_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we need to subsample down to match the smallest population\n",
    "# Let's make it even a little smaller so that way it's got some randomness as well\n",
    "\n",
    "target_pop_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "northern_samples = pop_filtered.filter(pl.col(\"Population3\") == \"Northern\").get_column(\"ID\").to_list()\n",
    "enderby_samples = pop_filtered.filter(pl.col(\"Population3\") == \"Enderby\").get_column(\"ID\").to_list()\n",
    "campbell_samples = pop_filtered.filter(pl.col(\"Population3\") == \"Campbell\").get_column(\"ID\").to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(x) for x in [northern_samples, enderby_samples, campbell_samples]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into dict\n",
    "pop_samples = {\n",
    "    \"Northern\": northern_samples,\n",
    "    \"Enderby\": enderby_samples,\n",
    "    \"Campbell\": campbell_samples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subset(pop_samples, target_pop_size, replicate):\n",
    "    # Subsample each population down to target_pop_size\n",
    "    subsampled_samples = {}\n",
    "    for pop, samples in pop_samples.items():\n",
    "        subsampled_samples[pop] = random.sample(samples, target_pop_size)\n",
    "\n",
    "    # Then run bcftools view to subset for only those samples\n",
    "    subset_bcf = f\"subset_{target_pop_size}.bcf\"\n",
    "    subset_samples = [x for sublist in subsampled_samples.values() for x in sublist]\n",
    "    subset_samples = \",\".join(subset_samples)\n",
    "    !bcftools view -O b -o {subset_bcf} -s {subset_samples} {bcf_file}\n",
    "    \n",
    "    # Then run plink2 PCA on the subset\n",
    "    !pixi run plink2 --bcf {subset_bcf} --pca --out subset_{target_pop_size} --allow-extra-chr --vcf-half-call missing\n",
    "\n",
    "    df = pl.read_csv(\"subset_28.eigenvec\", separator=\"\\t\")\n",
    "    df = df.to_pandas()\n",
    "\n",
    "    # Merge with metadata\n",
    "    df = df.merge(pop_filtered.to_pandas(), left_on=\"#IID\", right_on=\"ID\")\n",
    "\n",
    "    fig = px.scatter(df, x=\"PC1\", y=\"PC2\", color=\"Population3\", hover_data=[\"ID\"])\n",
    "    fig.write_image(f\"pca_subset_rep{replicate}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 100 times\n",
    "for i in range(100):\n",
    "    run_subset(pop_samples, target_pop_size, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
