{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn and polars\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"plotly_mimetype+notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up metadata from \"DNA from hoiho genomesv2.csv\"\n",
    "metadata = pl.read_csv(\n",
    "    \"DNA from hoiho genomesv2_id_updated_10Oct2024.csv\", separator=\"\\t\"\n",
    ")\n",
    "# C101/CE9 should just be called CE9\n",
    "# P29 has a space at the end\n",
    "\n",
    "# Let's fix that\n",
    "# First to fix is P29\n",
    "metadata = metadata.with_columns(\n",
    "    pl.col(\"ID\").replace(\"P29 \", \"P29\").alias(\"ID\")\n",
    ")\n",
    "\n",
    "# Next is C101/CE9\n",
    "metadata = metadata.with_columns(\n",
    "    pl.col(\"ID\").replace(\"C101/CE9\", \"CE9\").alias(\"ID\")\n",
    ")\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = pl.read_csv(\"sparsity\", has_header=False, new_columns=[\"Contig\", \"ID\"], separator=\"\\t\")\n",
    "\n",
    "# How many individuals are there?\n",
    "joined = metadata.join(sparsity, on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.load(\"matrix.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command\n",
    "```\n",
    "bcftools +check-sparsity --n-markers 100 merged.unfiltered.bcf > sparsity\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we need a matrix, with individuals as rows and contigs as columns\n",
    "\n",
    "# First, let's get the contigs\n",
    "contigs = sparsity.select(\"Contig\").unique().sort(\"Contig\")\n",
    "contigs = contigs.to_pandas()\n",
    "contigs = contigs[\"Contig\"].tolist()\n",
    "\n",
    "# Now let's get the individuals\n",
    "individuals = metadata.select(\"ID\").unique().sort(\"ID\")\n",
    "individuals = individuals.to_pandas()\n",
    "individuals = individuals[\"ID\"].tolist()\n",
    "\n",
    "# Now we need to fill in the matrix\n",
    "# We'll start with a matrix of zeros\n",
    "\n",
    "matrix = np.zeros((len(individuals), len(contigs)))\n",
    "\n",
    "# Now we need to fill in the matrix\n",
    "for i, individual in enumerate(individuals):\n",
    "    # Make this faster, by filtering for ID first\n",
    "    indiv_df = joined.filter(pl.col(\"ID\") == individual)\n",
    "    print(\"{}/{}\".format(i, len(individuals)))\n",
    "\n",
    "    for j, contig in enumerate(contigs):\n",
    "        if indiv_df.filter(pl.col(\"Contig\") == contig).shape[0] > 0:\n",
    "            matrix[i, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"matrix.npy\", matrix)\n",
    "# metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort individuals by \"Mainland vs Subs\"\n",
    "metadata = metadata.sort(\"Subs v Mainland\")\n",
    "\n",
    "# Update matrix to the new order\n",
    "new_order = metadata.select(\"ID\").to_pandas()\n",
    "new_order = new_order[\"ID\"].tolist()\n",
    "\n",
    "old_order = individuals\n",
    "\n",
    "# Reorder matrix\n",
    "new_matrix = np.zeros((len(individuals), len(contigs)))\n",
    "\n",
    "for i, individual in enumerate(new_order):\n",
    "    idx = old_order.index(individual)\n",
    "    new_matrix[i, :] = matrix[idx, :]\n",
    "\n",
    "# Which is first and where is the border (index, numerically)\n",
    "\n",
    "# First, let's get the border\n",
    "border = metadata.filter(pl.col(\"Subs v Mainland\") == \"Mainland\").shape[0]\n",
    "border\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as a heatmap for now\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "sns.heatmap(new_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA of sparsity matrix and plot\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(matrix)\n",
    "\n",
    "# Get the transformed data\n",
    "transformed = pca.transform(matrix)\n",
    "\n",
    "# Plot\n",
    "px.scatter(x=transformed[:, 0], y=transformed[:, 1], color=individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1]SEX        [2]Sample       [3]Predicted sex        [4]log P(Haploid)/nSites        [5]log P(Diploid)/nSites        [6]nSites       [7]Score: F < 0 < M ($4-$5)\n",
    "\n",
    "guess_ploidy = pl.read_csv(\"guess_ploidy\", has_header=False, separator=\"\\t\", skip_rows=3, new_columns=[\"_\", \"ID\", \"__\", \"log P(Haploid)/nSites\", \"log P(Diploid)/nSites\", \"nSites\", \"Score\"])\n",
    "guess_ploidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(y=guess_ploidy[\"log P(Haploid)/nSites\"], color=guess_ploidy[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contigs = pl.read_csv(\"all_contigs\", has_header=False)[:, 0].to_list()\n",
    "# Remove the starting \">\"\n",
    "all_contigs = [contig[1:] for contig in all_contigs]\n",
    "all_contigs[0:2]\n",
    "len(all_contigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_sex_chrs = pl.read_csv(\"possible_sex_chrs\", has_header=False)[:, 0].to_list()\n",
    "\n",
    "# Remove possible sex chrs from all contigs\n",
    "all_contigs = [contig for contig in all_contigs if contig not in possible_sex_chrs]\n",
    "len(all_contigs)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as non_sex_contigs, one item per line\n",
    "with open(\"non_sex_contigs\", \"w\") as f:\n",
    "    for contig in all_contigs:\n",
    "        f.write(contig + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
