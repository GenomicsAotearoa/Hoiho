{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCF_FILE = \"../merged.a9.filtered.qual20_fmissing0.2.2alleles.snpsonly.pp6.19.n23_25_yep14.removed.bcf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split BCF into pop assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_df = pl.read_csv(\"../pop_assignments.txt\", separator=\" \" )\n",
    "pops_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output file for each pop\n",
    "for pop in pops_df[\"Population3\"].unique():\n",
    "    pop_df = pops_df.filter(pl.col(\"Population3\") == pop)\n",
    "    # Only write out the sample ID, one per line\n",
    "    pop_df.select(\"ID\").write_csv(f\"pop_samples_{pop}.txt\", separator=\"\\t\", include_header=False)\n",
    "    !bcftools view --threads 48 -S pop_samples_{pop}.txt --force-samples -o pop_{pop}.vcf.gz -Oz {BCF_FILE} -a -q 0.05:minor -U\n",
    "    !vcftools --SNPdensity 100000 --gzvcf pop_{pop}.vcf.gz --out pop_{pop}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Circos format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_snpden_to_circos(pop_name, pop_snpden_file):\n",
    "    snpden_df = pl.read_csv(pop_snpden_file, separator=\"\\t\")\n",
    "    # Get the mean for snpden_df VARIANTS/KB\n",
    "    print(f\"Mean: {snpden_df['VARIANTS/KB'].mean()}\")\n",
    "    print(f\"Std Dev: {snpden_df['VARIANTS/KB'].std()}\")\n",
    "\n",
    "    bin_size = 100_000\n",
    "    # Take the largest mean from any pop, and the largest std.dev from any pop\n",
    "    max_trim = 0.5863066764490095 + (2.5 * 0.5368753908840088)\n",
    "    max_variant_count = 0\n",
    "    # Iterate through the rows and convert to circos format\n",
    "    with open(f\"{pop_name}.snpden.txt\", \"w\") as f:\n",
    "        for i in range(0, snpden_df.height):\n",
    "            # Export CHROM, BIN_START, BIN_START + bin_size, VARIANTS/KB\n",
    "            chrom = snpden_df[i, \"CHROM\"]\n",
    "            bin_start = snpden_df[i, \"BIN_START\"]\n",
    "            bin_end = bin_start + bin_size\n",
    "            variant_count = snpden_df[i, \"VARIANTS/KB\"]\n",
    "            max_variant_count = max(max_variant_count, variant_count)\n",
    "            if variant_count > max_trim:\n",
    "                variant_count = max_trim\n",
    "            variant_count = round(variant_count, 4)\n",
    "            f.write(f\"{chrom}\\t{bin_start}\\t{bin_end}\\t{variant_count}\\n\")\n",
    "    print(max_variant_count)\n",
    "\n",
    "# Run for all 3 pops\n",
    "convert_snpden_to_circos(\"pop_Northern\", \"pop_Northern.snpden\")\n",
    "convert_snpden_to_circos(\"pop_Campbell\", \"pop_Campbell.snpden\")\n",
    "convert_snpden_to_circos(\"pop_Enderby\", \"pop_Enderby.snpden\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snp density output should be like so:\n",
    "\n",
    "# S1 0 100000 0.05\n",
    "# S1 100000 200000 0.01\n",
    "# S1 200000 300000 0.05\n",
    "# S1 300000 400000 0.98\n",
    "# S1 400000 500000 2\n",
    "# S1 500000 600000 3.89\n",
    "# S1 600000 700000 2.88\n",
    "# S1 700000 800000 3.54\n",
    "# S1 800000 900000 4.71\n",
    "\n",
    "# Let's do 1 per population tho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vcftools --gzvcf ../merged.a9.filtered.qual20_fmissing0.2.2alleles.snpsonly.pp6.19.n23_25_yep14.removed.vcf.gz --weir-fst-pop pop_samples_Campbell.txt --weir-fst-pop pop_samples_Enderby.txt  --fst-window-size 100000 --out campbell_vs_enderby\n",
    "!vcftools --gzvcf ../merged.a9.filtered.qual20_fmissing0.2.2alleles.snpsonly.pp6.19.n23_25_yep14.removed.vcf.gz --weir-fst-pop pop_samples_Campbell.txt --weir-fst-pop pop_samples_Northern.txt --fst-window-size 100000 --out campbell_vs_northern\n",
    "!vcftools --gzvcf ../merged.a9.filtered.qual20_fmissing0.2.2alleles.snpsonly.pp6.19.n23_25_yep14.removed.vcf.gz --weir-fst-pop pop_samples_Enderby.txt  --weir-fst-pop pop_samples_Northern.txt --fst-window-size 100000 --out enderby_vs_northern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circos heatmap format is: S1      1666378 1766263 15\n",
    "\n",
    "def process_fst_to_circos(pop_name, pop_file):\n",
    "    fst_df = pl.read_csv(pop_file, separator=\"\\t\")\n",
    "    cur_min = 9999999999.9\n",
    "    cur_max = 0.0\n",
    "    with open(f\"{pop_name}.fst.circos.txt\", \"w\") as f:\n",
    "        for i in range(0, fst_df.height):\n",
    "            # Output CHROM, BIN_START, BIN_END, WEIGHTED_FST\n",
    "            f.write(f\"{fst_df[i, 'CHROM']}\\t{fst_df[i, 'BIN_START']}\\t{fst_df[i, 'BIN_END']}\\t{round(fst_df[i, 'WEIGHTED_FST'], 4)}\\n\")\n",
    "            cur_max = max(cur_max, fst_df[i, 'WEIGHTED_FST'])\n",
    "            cur_min = min(cur_min, fst_df[i, 'WEIGHTED_FST'])\n",
    "    print(f\"{pop_name} - Max: {cur_max}, Min: {cur_min}\")\n",
    "\n",
    "process_fst_to_circos(\"Campbell_vs_Northern\", \"campbell_vs_northern.windowed.weir.fst\")\n",
    "process_fst_to_circos(\"Campbell_vs_Enderby\", \"campbell_vs_enderby.windowed.weir.fst\")\n",
    "process_fst_to_circos(\"Enderby_vs_Northern\", \"enderby_vs_northern.windowed.weir.fst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vcftools --gzvcf pop_Campbell.vcf.gz --out campbell --het\n",
    "!vcftools --gzvcf pop_Campbell.vcf.gz --out campbell --missing-site\n",
    "!vcftools --gzvcf pop_Campbell.vcf.gz --out campbell --TajimaD 100000 \n",
    "!vcftools --gzvcf pop_Campbell.vcf.gz --out campbell --site-pi \n",
    "!vcftools --gzvcf pop_Campbell.vcf.gz --out campbell --window-pi 100000\n",
    "\n",
    "# pop_Enderby.vcf.gz and pop_Northern.vcf.gz\n",
    "!vcftools --gzvcf pop_Enderby.vcf.gz --out enderby --het\n",
    "!vcftools --gzvcf pop_Enderby.vcf.gz --out enderby --missing-site\n",
    "!vcftools --gzvcf pop_Enderby.vcf.gz --out enderby --TajimaD 100000\n",
    "!vcftools --gzvcf pop_Enderby.vcf.gz --out enderby --site-pi\n",
    "!vcftools --gzvcf pop_Enderby.vcf.gz --out enderby --window-pi 100000\n",
    "\n",
    "!vcftools --gzvcf pop_Northern.vcf.gz --out northern --het\n",
    "!vcftools --gzvcf pop_Northern.vcf.gz --out northern --missing-site\n",
    "!vcftools --gzvcf pop_Northern.vcf.gz --out northern --TajimaD 100000\n",
    "!vcftools --gzvcf pop_Northern.vcf.gz --out northern --site-pi\n",
    "!vcftools --gzvcf pop_Northern.vcf.gz --out northern --window-pi 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tajimasd_to_circos(pop_name, pop_file):\n",
    "    fst_df = pl.read_csv(pop_file, separator=\"\\t\")\n",
    "    cur_max = 0.0\n",
    "    cur_min = 9999999999.0\n",
    "    with open(f\"{pop_name}.tajimasd.circos.txt\", \"w\") as f:\n",
    "        for i in range(0, fst_df.height):\n",
    "            # Output CHROM, BIN_START, BIN_END, WEIGHTED_FST\n",
    "            f.write(f\"{fst_df[i, 'CHROM']}\\t{fst_df[i, 'BIN_START']}\\t{fst_df[i, 'BIN_START']+100000}\\t{round(fst_df[i, 'TajimaD'], 4)}\\n\")\n",
    "            cur_max = max(cur_max, fst_df[i, 'TajimaD'])\n",
    "            cur_min = min(cur_min, fst_df[i, 'TajimaD'])\n",
    "    print(f\"{pop_name} Tajima's D - Max: {cur_max}, Min: {cur_min}\")\n",
    "\n",
    "process_tajimasd_to_circos(\"Campbell\", \"campbell.Tajima.D\")\n",
    "process_tajimasd_to_circos(\"Enderby\", \"enderby.Tajima.D\")\n",
    "process_tajimasd_to_circos(\"Northern\", \"northern.Tajima.D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst = pd.read_csv(\"Fst_founders_offspring.windowed.weir.fst\", sep=\"\\t\")\n",
    "fst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"founders_vs_offspring_fst.scatter\", \"w\") as writer:\n",
    "    \n",
    "    for j,k in fst.iterrows():\n",
    "        writer.write(\"\\t\".join(map(str, [k['CHROM'], k['BIN_START'], k['BIN_END'], k['MEAN_FST']])))\n",
    "        writer.write(\"\\n\")\n",
    "    #print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.min(fst['MEAN_FST']), np.max(fst['MEAN_FST'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snpden = pd.read_csv(\"snpden.hist\", sep=\"\\s+\", header=None)\n",
    "[np.min(snpden[3]), np.max(snpden[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roh_data = pd.read_csv(\"data/bcftoolsroh_founders\", sep=\"\\t\", header=None, skiprows=4)\n",
    "roh_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roh = defaultdict(int)\n",
    "\n",
    "for j,row in roh_data.iterrows():\n",
    "    roh[(row[2], row[3], row[4])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(roh.keys())[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"founders_roh.heatmap\", \"w\") as writer:\n",
    "    for j, group in itertools.groupby(roh, lambda x: x[0]):\n",
    "        roh_count = Counter()\n",
    "        roh_positions = np.concatenate((*map(lambda x: np.arange(x[1], x[2]), group),))\n",
    "        counts = Counter(roh_positions)\n",
    "\n",
    "        intervals = defaultdict(int)\n",
    "\n",
    "        istart = list(counts.keys())[0]\n",
    "        iend = istart\n",
    "        qty = list(counts.values())[0]\n",
    "\n",
    "        for k in counts:\n",
    "            v = counts[k]\n",
    "            if k - iend > 1 or v != qty:\n",
    "                intervals[(istart, iend)] = qty\n",
    "                istart = k\n",
    "                iend = k\n",
    "                qty = v\n",
    "            else:\n",
    "                iend = k\n",
    "\n",
    "        # And the final one...\n",
    "        intervals[(istart, iend)] = qty\n",
    "\n",
    "        for k,v in intervals.items():\n",
    "            writer.write(\"\\t\".join(map(str, [j, k[0], k[1], v])))\n",
    "            writer.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roh_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(roh_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intervals = defaultdict(int)\n",
    "\n",
    "istart = list(counts.keys())[0]\n",
    "iend = istart\n",
    "qty = list(counts.values())[0]\n",
    "\n",
    "for k in counts:\n",
    "    v = counts[k]\n",
    "    if k - iend > 1 or v != qty:\n",
    "        intervals[(istart, iend)] = qty\n",
    "        istart = k\n",
    "        iend = k\n",
    "        qty = v\n",
    "    else:\n",
    "        iend = k\n",
    "\n",
    "# And the final one...\n",
    "intervals[(istart, iend)] = qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"founders_roh.heatmap\", \"w\") as writer:\n",
    "    for k,v in intervals.items():\n",
    "        writer.write(\"\\t\".join(map(str, [\"S1\", k[0], k[1], v])))\n",
    "        writer.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(list(intervals.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roh_data = pd.read_csv(\"data/bcftoolsroh_offspring\", sep=\"\\t\", header=None, skiprows=4)\n",
    "roh_data.head()\n",
    "roh = defaultdict(int)\n",
    "\n",
    "for j,row in roh_data.iterrows():\n",
    "    roh[(row[2], row[3], row[4])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"offspring_roh.heatmap\", \"w\") as writer:\n",
    "    for j, group in itertools.groupby(roh, lambda x: x[0]):\n",
    "        roh_count = Counter()\n",
    "        roh_positions = np.concatenate((*map(lambda x: np.arange(x[1], x[2]), group),))\n",
    "        counts = Counter(roh_positions)\n",
    "\n",
    "        intervals = defaultdict(int)\n",
    "\n",
    "        istart = list(counts.keys())[0]\n",
    "        iend = istart\n",
    "        qty = list(counts.values())[0]\n",
    "\n",
    "        for k in counts:\n",
    "            v = counts[k]\n",
    "            if k - iend > 1 or v != qty:\n",
    "                intervals[(istart, iend)] = qty\n",
    "                istart = k\n",
    "                iend = k\n",
    "                qty = v\n",
    "            else:\n",
    "                iend = k\n",
    "\n",
    "        # And the final one...\n",
    "        intervals[(istart, iend)] = qty\n",
    "\n",
    "        for k,v in intervals.items():\n",
    "            writer.write(\"\\t\".join(map(str, [j, k[0], k[1], v])))\n",
    "            writer.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counts = Counter(roh_positions)\n",
    "intervals = defaultdict(int)\n",
    "\n",
    "istart = list(counts.keys())[0]\n",
    "iend = istart\n",
    "qty = list(counts.values())[0]\n",
    "\n",
    "for k in counts:\n",
    "    v = counts[k]\n",
    "    if k - iend > 1 or v != qty:\n",
    "        intervals[(istart, iend)] = qty\n",
    "        istart = k\n",
    "        iend = k\n",
    "        qty = v\n",
    "    else:\n",
    "        iend = k\n",
    "\n",
    "# And the final one...\n",
    "intervals[(istart, iend)] = qty\n",
    "\n",
    "with open(\"offspring_roh.heatmap\", \"w\") as writer:\n",
    "    for k,v in intervals.items():\n",
    "        writer.write(\"\\t\".join(map(str, [\"S1\", k[0], k[1], v])))\n",
    "        writer.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
