{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from cyvcf2 import VCF\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all species from halstats file\n",
    "seabirds = pl.read_csv(\"seabird_alignment_halstats\", skip_lines=4)['GenomeName'].to_list()\n",
    "seabirds = [s for s in seabirds if s is not None]\n",
    "seabirds = [s for s in seabirds if not s.startswith(\"Anc\")]\n",
    "# Filter out c90 (it's subantarctic islands and we have them from the regular pop)\n",
    "seabirds = [s for s in seabirds if not s.startswith(\"c90\")]\n",
    "seabirds = [s for s in seabirds if not s.startswith(\"a9\")] # We have a9 in the SNPs as well\n",
    "# Remove Megadyptes_antipodes\n",
    "seabirds = [s for s in seabirds if not s.startswith(\"Megadyptesantipodes\")]\n",
    "# Assert a9 is not in seabirds\n",
    "assert \"a9\" not in seabirds, \"a9 should not be in seabirds\"\n",
    "len(seabirds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "penguin_prefixes = (\n",
    "    \"Aptenodytes\",   # king & emperor\n",
    "    \"Spheniscus\",    # banded penguins\n",
    "    \"Pygoscelis\",    # brush‑tails\n",
    "    \"Eudyptula\",     # little penguins\n",
    "    \"Eudyptes\"       # crested penguins (includes Eudyptesmoseleyi)\n",
    ")\n",
    "\n",
    "penguins = [sp for sp in seabirds if sp.startswith(penguin_prefixes)]\n",
    "print(penguins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aDNA\n",
    "def extract_sites(filename):\n",
    "    df = pl.scan_csv(filename, separator=\"\\t\", low_memory=True)\n",
    "    # Remove sites that are hemi\n",
    "    #filtered = df.filter(pl.col(\"GT\").is_in([\"0/0\", \"0/1\", \"1/0\", \"1/1\"]))\n",
    "    filtered = df.filter(pl.col(\"modern_GT\").is_in([\"0/0\", \"0/1\", \"1/0\", \"1/1\"]))\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "# Example usage:\n",
    "waitaha_sites = extract_sites('adna/waitaha/waitaha.tsv').filter(pl.col('reason') == 'lifted_and_genotyped')\n",
    "richdalei_sites = extract_sites('adna/richdalei/richdalei.tsv').filter(pl.col('reason') == 'lifted_and_genotyped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's collect and then save the dataframes, to speed up downstream processing\n",
    "waitaha_sites = waitaha_sites.collect()\n",
    "richdalei_sites = richdalei_sites.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "richdalei_sites.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find intersecting sites, both have the same column names\n",
    "waitaha_sites = waitaha_sites.rename({\"modern_GT\": \"waitaha_GT\"})\n",
    "richdalei_sites = richdalei_sites.rename({\"modern_GT\": \"richdalei_GT\"})\n",
    "\n",
    "# Find intersecting sites - Join on modern_chrom and modern_pos\n",
    "intersecting_sites = waitaha_sites.join(richdalei_sites, on=[\"modern_chrom\", \"modern_pos\"], how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecting_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save them to parquet files\n",
    "intersecting_sites.write_parquet('adna/intersecting_sites.parquet')\n",
    "waitaha_sites.write_parquet('adna/waitaha/waitaha_filtered.parquet')\n",
    "richdalei_sites.write_parquet('adna/richdalei/richdalei_filtered.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the saved files (skip to this cell if we have already saved them)\n",
    "waitaha_sites = pl.scan_parquet('adna/waitaha/waitaha_filtered.parquet')\n",
    "richdalei_sites = pl.scan_parquet('adna/richdalei/richdalei_filtered.parquet')\n",
    "intersecting_sites = pl.scan_parquet('adna/intersecting_sites.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many waitaha_sites are 0/0 ?\n",
    "waitaha_00 = waitaha_sites.filter(pl.col(\"waitaha_GT\") == \"0/0\").collect().shape[0]\n",
    "print(f\"Waitaha 0/0: {waitaha_00}\")\n",
    "# How many waitaha sites are 0/0, and then 1/1?\n",
    "waitaha_01 = waitaha_sites.filter(pl.col(\"waitaha_GT\") == \"0/1\").collect().shape[0]\n",
    "print(f\"Waitaha 0/1: {waitaha_01}\")\n",
    "waitaha_11 = waitaha_sites.filter(pl.col(\"waitaha_GT\") == \"1/1\").collect().shape[0]\n",
    "print(f\"Waitaha 1/1: {waitaha_11}\")\n",
    "\n",
    "# It's not phased, but a sanity check that costs nothing is still a good idea\n",
    "waitaha_10 = waitaha_sites.filter(pl.col(\"waitaha_GT\") == \"1/0\").collect().shape[0]\n",
    "print(f\"Waitaha 1/0: {waitaha_10}\")\n",
    "\n",
    "# The same for richdalei\n",
    "richdalei_00 = richdalei_sites.filter(pl.col(\"richdalei_GT\") == \"0/0\").collect().shape[0]\n",
    "print(f\"Richdalei 0/0: {richdalei_00}\")\n",
    "richdalei_01 = richdalei_sites.filter(pl.col(\"richdalei_GT\") == \"0/1\").collect().shape[0]\n",
    "print(f\"Richdalei 0/1: {richdalei_01}\")\n",
    "richdalei_11 = richdalei_sites.filter(pl.col(\"richdalei_GT\") == \"1/1\").collect().shape[0]\n",
    "print(f\"Richdalei 1/1: {richdalei_11}\")\n",
    "richdalei_10 = richdalei_sites.filter(pl.col(\"richdalei_GT\") == \"1/0\").collect().shape[0]\n",
    "print(f\"Richdalei 1/0: {richdalei_10}\")\n",
    "\n",
    "#richdalei_00 = richdalei_sites.filter(pl.col(\"GT\") == \"0/0\").collect().shape[0]\n",
    "#print(f\"Waitaha 0/0: {waitaha_00}, Richdalei 0/0: {richdalei_00}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========\n",
    "# Parameters\n",
    "# ==========\n",
    "input_vcf = \"merged.a9.filtered.qual99_fmissing0.2.maf0.05.biallelic.bcf\"   # path to your filtered, biallelic VCF\n",
    "num_snps = 200                 # how many SNPs to randomly sample\n",
    "num_replicates = 10             # how many replicates to generate\n",
    "output_prefix = \"random_snps_adna_200\"   # prefix for output FASTA files\n",
    "random_seed = None              # set to an integer for reproducible results, e.g. 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_seed is not None:\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Read in the VCF variants\n",
    "# ============================\n",
    "vcf = VCF(input_vcf)\n",
    "records = [variant for variant in vcf]  # store all variants in memory\n",
    "samples = vcf.samples\n",
    "\n",
    "vcf_sites = pl.DataFrame({\n",
    "    \"chrom\": [record.CHROM for record in records],\n",
    "    \"pos\": [record.POS for record in records],\n",
    "    \"VCF_ref\": [record.REF for record in records],\n",
    "    \"VCF_alt\": [record.ALT[0] if record.ALT else None for record in records],\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(records)} variants from {input_vcf}.\")\n",
    "print(f\"Samples in VCF: {samples}\")\n",
    "\n",
    "# Check we have enough variants to sample\n",
    "if len(records) < num_snps:\n",
    "    raise ValueError(\n",
    "        f\"ERROR: The VCF has only {len(records)} variants, \"\n",
    "        f\"but you requested {num_snps}.\"\n",
    "    )\n",
    "\n",
    "# Add in aDNA samples\n",
    "samples.extend([\"waitaha\", \"richdalei\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waitaha_sites.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = vcf_sites.join(\n",
    "    intersecting_sites.collect(),\n",
    "    left_on=[\"chrom\", \"pos\"],\n",
    "    right_on=[\"modern_chrom\", \"modern_pos\"],\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = intersection.select((pl.col(\"chrom\").alias(\"CHROM\"), pl.col(\"pos\").alias(\"POS\"))).to_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waitaha_sites = waitaha_sites.collect()\n",
    "richdalei_sites = richdalei_sites.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there's a SNP\n",
    "# halSnps --tsv snps --refSequence ptg000057l --start 63660 --length 100 /mnt/data/seabirds.hal a9 Eudyptesmoseleyi_genomic\n",
    "\n",
    "# If no SNP, see if it's a reference allele or missing sequence\n",
    "# halAlignmentDepth /mnt/data/seabirds.hal a9 --targetGenomes Eudyptesmoseleyi_genomic --refSequence ptg000057l --start 63660 --length 100\n",
    "\n",
    "# hal snp or missing function\n",
    "\n",
    "hal_file = \"/mnt/data/seabirds.hal\"\n",
    "\n",
    "def hal_snp_or_missing(chrom, pos, samples):\n",
    "\n",
    "    samples_state = { sample: None for sample in samples }\n",
    "\n",
    "    # Convert samples to a comma-separated string\n",
    "    samples_str = \",\".join(samples)\n",
    "\n",
    "    # Subtract 1 from pos for 0-based indexing\n",
    "    pos -= 1\n",
    "    snp_command = f\"/mnt/data/development/hoiho/wga/cactus/cactus-bin-v2.9.7/bin/halSnps --tsv snps.tmp --refSequence {chrom} --start {pos} --length 1 {hal_file} a9 {samples_str}\"\n",
    "    missing_command = f\"/mnt/data/development/hoiho/wga/cactus/cactus-bin-v2.9.7/bin/halAlignmentDepth {hal_file} a9 --targetGenomes {samples_str} --refSequence {chrom} --start {pos} --length 1 --noAncestors\"\n",
    "\n",
    "    # Run the snp_command, capture the stdout and read the snps.tmp\n",
    "    import subprocess\n",
    "    try:\n",
    "        # Don't print stdout, just check for errors\n",
    "        subprocess.run(snp_command, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        snp_data = pl.read_csv(\"snps.tmp\", separator=\"\\t\")\n",
    "        for sample in samples:\n",
    "            if sample in snp_data.columns:\n",
    "                # Get the column which is the sample name\n",
    "                state = snp_data[sample].to_list()\n",
    "                if len(state) > 0 and state[0] is not None:\n",
    "                    samples_state[sample] = state[0].upper()\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running command: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # For all remaining nones, create a new sample_str\n",
    "    missing_samples = [sample for sample, state in samples_state.items() if state is None]\n",
    "    if missing_samples:\n",
    "        try:\n",
    "            # This is just as stdout, so capture it as depth_out\n",
    "            depth_out = subprocess.run(missing_command, shell=True, check=True, capture_output=True, text=True)\n",
    "            depth_lines = depth_out.stdout.strip().split(\"\\n\")[1:]\n",
    "            if int(depth_lines[0]) >= 1:\n",
    "                # If the depth is >= 1, then it's a reference allele\n",
    "                for sample in missing_samples:\n",
    "                    samples_state[sample] = \"REF\"\n",
    "            # Otherwise leave it as None\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error running command: {e}\")\n",
    "            return None\n",
    "    return samples_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecting_sites.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long, skip and used save (if possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cactus_samples_rows = []\n",
    "\n",
    "for row in intersecting_sites.collect().iter_rows(named=True):\n",
    "    chrom = row['modern_chrom']\n",
    "    pos = row['modern_pos']\n",
    "    sample_states = hal_snp_or_missing(chrom, pos, seabirds)\n",
    "    vcf_state = vcf_sites.filter(pl.col(\"chrom\") == chrom).filter(pl.col(\"pos\") == pos).select([\"VCF_ref\", \"VCF_alt\"]).to_dicts()[0]\n",
    "    vcf_ref = vcf_state['VCF_ref']\n",
    "    vcf_alt = vcf_state['VCF_alt']\n",
    "\n",
    "    if sample_states is not None:\n",
    "        # Create a new row with the sample states\n",
    "        new_row = {\n",
    "            \"modern_chrom\": chrom,\n",
    "            \"modern_pos\": pos,\n",
    "        }\n",
    "\n",
    "        # Mark third alleles as Missing (None)\n",
    "        for sample, state in sample_states.items():\n",
    "            if state == \"REF\":\n",
    "                new_row[sample] = vcf_state['VCF_ref']\n",
    "\n",
    "            if state not in [vcf_ref, vcf_alt, None]:\n",
    "                state = None\n",
    "\n",
    "            # Now convert to the numeric representation\n",
    "            new_col = f\"{sample}_GT\"\n",
    "            new_row[new_col] = None  # Default to None\n",
    "            if state == vcf_state['VCF_ref']:\n",
    "                new_row[new_col] = \"0/0\"\n",
    "            elif state == vcf_state['VCF_alt']:\n",
    "                new_row[new_col] = \"1/1\"\n",
    "            elif state == \"REF\":\n",
    "                new_row[new_col] = \"0/0\"\n",
    "            elif state == \"N\":\n",
    "                new_row[new_col] = None\n",
    "            elif state is None:\n",
    "                new_row[new_col] = None\n",
    "            else:\n",
    "                print(f\"Unexpected state for {sample} at {chrom}:{pos}: {state}\")\n",
    "                new_row[new_col] = None\n",
    "\n",
    "        cactus_samples_rows.append(new_row)\n",
    "\n",
    "# Create a new dict to turn into a dataframe for joining later\n",
    "#cactus_samples_df = pl.DataFrame(cactus_samples_rows)\n",
    "#cactus_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cactus_samples_df = pl.DataFrame(cactus_samples_rows, infer_schema_length=20000)\n",
    "cactus_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cactus_samples_df since it takes a lot of hal calls to generate\n",
    "# cactus_samples_df.write_parquet('adna/cactus_samples.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cactus_samples_df = pl.read_parquet('adna/cactus_samples.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows in cactus_samples_df have >= 80% not None (null in Polars)?\n",
    "num_samples = len(seabirds)\n",
    "min_non_null = int(num_samples * 0.8)\n",
    "cactus_samples_df = cactus_samples_df.with_columns(\n",
    "    pl.sum_horizontal([pl.col(f\"{sample}_GT\").is_not_null() for sample in seabirds]).alias(\"num_non_null\")\n",
    ")\n",
    "cactus_samples_df = cactus_samples_df.filter(pl.col(\"num_non_null\") >= min_non_null)\n",
    "\n",
    "cactus_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ptg000057l\"\t99576\n",
    "# vcf_sites.filter(pl.col(\"chrom\") == \"ptg000057l\").filter(pl.col(\"pos\") == 99576).select([\"VCF_ref\", \"VCF_alt\"]).to_dicts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_replicates = 1 \n",
    "\n",
    "for rep_index in range(1, num_replicates + 1):\n",
    "    snps_used = 0\n",
    "    print(f\"Generating replicate {rep_index} of {num_replicates} ...\")\n",
    "\n",
    "    # 2a. Randomly sample indices from possible sites\n",
    "    # chosen_indices = random.sample(range(len(possible_sites)), num_snps)\n",
    "    # chosen_sites = possible_sites[chosen_indices]\n",
    "\n",
    "    sample2seq = {sample: [] for sample in samples}\n",
    "    sample2seq_msa = {sample: [] for sample in samples}\n",
    "\n",
    "    # 2c. Process each chosen site\n",
    "    for site in chosen_sites:\n",
    "        chrom, pos = site['CHROM'], site['POS']\n",
    "        if chrom is None or pos is None:\n",
    "            print(f\"WARNING: Skipping site with None values: {site}\")\n",
    "            break\n",
    "        \n",
    "        # Use a generator to find the record, which is more memory-efficient\n",
    "        records = vcf(f\"{chrom}:{pos}\")\n",
    "        record = next(records, None)\n",
    "\n",
    "        # For FASTA, we need ref_allele and alt_allele\n",
    "        if record is not None:\n",
    "            ref_allele = record.REF\n",
    "            alt_allele = record.ALT[0] if record.ALT else None\n",
    "\n",
    "        if record is None:\n",
    "            print(f\"WARNING: No record found for {chrom}:{pos}. Skipping.\")\n",
    "            # Append a missing data placeholder for all samples for this site\n",
    "            for sample in samples:\n",
    "                sample2seq[sample].append('-')\n",
    "                sample2seq_msa[sample].append('N')\n",
    "            continue\n",
    "\n",
    "        # The rest of the processing for a found record\n",
    "        genotypes = record.genotypes\n",
    "\n",
    "        snps_used += 1\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            code = '-'  # Default to missing\n",
    "            if sample in [\"waitaha\", \"richdalei\"]:\n",
    "                loc = [record.CHROM, record.POS]\n",
    "                if sample == \"waitaha\":\n",
    "                    gt_list = waitaha_sites.filter(\n",
    "                        (pl.col(\"modern_chrom\") == loc[0]) & (pl.col(\"modern_pos\") == loc[1])\n",
    "                    )['waitaha_GT'].to_list()\n",
    "                else:  # sample == \"richdalei\"\n",
    "                    gt_list = richdalei_sites.filter(\n",
    "                        (pl.col(\"modern_chrom\") == loc[0]) & (pl.col(\"modern_pos\") == loc[1])\n",
    "                    )['richdalei_GT'].to_list()\n",
    "\n",
    "                if gt_list:\n",
    "                    gt = gt_list[0]\n",
    "                    if gt == \"0/0\":\n",
    "                        code = \"0\"\n",
    "                    elif gt in [\"0/1\", \"1/0\"]:\n",
    "                        code = \"1\"\n",
    "                    elif gt == \"1/1\":\n",
    "                        code = \"2\"\n",
    "\n",
    "            elif sample in vcf.samples:\n",
    "                g1, g2 = genotypes[i][0], genotypes[i][1]\n",
    "\n",
    "                if g1 >= 0 and g2 >= 0:\n",
    "                    if g1 == 0 and g2 == 0:\n",
    "                        code = '0'\n",
    "                    elif (g1 == 0 and g2 == 1) or (g1 == 1 and g2 == 0):\n",
    "                        code = '1'\n",
    "                    elif g1 == 1 and g2 == 1:\n",
    "                        code = '2'\n",
    "\n",
    "            sample2seq[sample].append(code)\n",
    "\n",
    "            # And do the same for MSA - Convert back to ACTGN (or the mix for heterozygotes)\n",
    "            if code == '0':\n",
    "                msa_code = ref_allele\n",
    "            elif code == '1':\n",
    "                # Have to use IUPAC codes for heterozygotes\n",
    "                if ref_allele == 'A' and alt_allele == 'C':\n",
    "                    msa_code = 'M'\n",
    "                elif ref_allele == 'A' and alt_allele == 'G':\n",
    "                    msa_code = 'R'\n",
    "                elif ref_allele == 'A' and alt_allele == 'T':\n",
    "                    msa_code = 'W'\n",
    "                elif ref_allele == 'C' and alt_allele == 'G':\n",
    "                    msa_code = 'S'\n",
    "                elif ref_allele == 'C' and alt_allele == 'T':\n",
    "                    msa_code = 'Y'\n",
    "                elif ref_allele == 'G' and alt_allele == 'T':\n",
    "                    msa_code = 'K'\n",
    "                elif ref_allele == 'A' and alt_allele == 'N':\n",
    "                    msa_code = 'A'\n",
    "                elif ref_allele == 'C' and alt_allele == 'N':\n",
    "                    msa_code = 'C'\n",
    "                elif ref_allele == 'G' and alt_allele == 'N':\n",
    "                    msa_code = 'G'\n",
    "                elif ref_allele == 'T' and alt_allele == 'N':\n",
    "                    msa_code = 'T'\n",
    "                elif ref_allele == 'N' and alt_allele == 'A':\n",
    "                    msa_code = 'A'\n",
    "                elif ref_allele == 'N' and alt_allele == 'C':\n",
    "                    msa_code = 'C'\n",
    "                elif ref_allele == 'N' and alt_allele == 'G':\n",
    "                    msa_code = 'G'\n",
    "            elif code == '2':\n",
    "                msa_code = alt_allele\n",
    "            else:\n",
    "                msa_code = '-'\n",
    "\n",
    "            sample2seq_msa[sample].append(msa_code)\n",
    "\n",
    "    # 2d. Write NEXUS for this replicate\n",
    "    out_nexus = f\"{output_prefix}_rep{rep_index}.nex\"\n",
    "    try:\n",
    "        with open(out_nexus, \"w\") as out_f:\n",
    "            # Header\n",
    "            out_f.write(\"#NEXUS\\n\")\n",
    "            out_f.write(\"[SNP matrix in integer format: 0=homREF, 1=het, 2=homALT, -=missing]\\n\\n\")\n",
    "            out_f.write(\"Begin data;\\n\")\n",
    "            out_f.write(f\"\\tDimensions ntax={len(samples)} nchar={num_snps};\\n\")\n",
    "            out_f.write('\\tFormat datatype=integerdata symbols=\"012\" gap=-;\\n')\n",
    "            out_f.write(\"\\tMatrix\\n\")\n",
    "\n",
    "            # Matrix lines\n",
    "            for sample in samples:\n",
    "                seq_str = \"\".join(sample2seq[sample])\n",
    "                out_f.write(f\"{sample}\\t{seq_str}\\n\")\n",
    "\n",
    "            out_f.write(\"\\t;\\nEnd;\\n\")\n",
    "        print(f\"  -> Wrote replicate {rep_index} NEXUS: {out_nexus}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file {out_nexus}: {e}\")\n",
    "\n",
    "    # 2e. Write FASTA for this replicate\n",
    "    out_fasta = f\"{output_prefix}_rep{rep_index}.fasta\"\n",
    "    try:\n",
    "        with open(out_fasta, \"w\") as out_f:\n",
    "            for sample in samples:\n",
    "                seq_str = \"\".join(sample2seq_msa[sample])\n",
    "                out_f.write(f\">{sample}\\n{seq_str}\\n\")\n",
    "        print(f\"  -> Wrote replicate {rep_index} FASTA: {out_fasta}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file {out_fasta}: {e}\")\n",
    "\n",
    "    # Explicitly clear the dictionary to free memory, though it will be\n",
    "    # garbage collected at the start of the next iteration anyway.\n",
    "    del sample2seq\n",
    "\n",
    "print(f\"All replicates done! SNPs used: {snps_used}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ['ptg000003l', 47510119] in waitaha_sites\n",
    "waitaha_sites.filter(\n",
    "    (pl.col(\"modern_chrom\") == \"ptg000015l\") & \n",
    "    (pl.col(\"modern_pos\") == 13069202)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there's a SNP\n",
    "# halSnps --tsv snps --refSequence ptg000057l --start 63660 --length 100 /mnt/data/seabirds.hal a9 Eudyptesmoseleyi_genomic\n",
    "\n",
    "# If no SNP, see if it's a reference allele or missing sequence\n",
    "# halAlignmentDepth /mnt/data/seabirds.hal a9 --targetGenomes Eudyptesmoseleyi_genomic --refSequence ptg000057l --start 63660 --length 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep_index in range(1, num_replicates + 1):\n",
    "    print(f\"Generating replicate {rep_index} of {num_replicates} ...\")\n",
    "\n",
    "    # 2a. Randomly sample SNPs from possible sites (waitaha sites, since it has the least)\n",
    "    # chosen_records = random.sample(records, num_snps)\n",
    "    # Get indices of random sites, we can't use the sample function on Polars DataFrame directly\n",
    "    chosen_indices = random.sample(range(len(possible_sites)), num_snps)\n",
    "    chosen_sites = possible_sites[chosen_indices]\n",
    "    chosen_records = []\n",
    "    for site in chosen_sites.iter_rows(named=True):\n",
    "        chrom, pos = site['chrom'], site['pos(1‑based)']\n",
    "        # Find the record that matches this chrom and pos\n",
    "        record = vcf(f\"{chrom}:{pos}\")\n",
    "        # Record is now a generator, let's get the first one\n",
    "        record = next(record, None)  # Get the first record or None if not found\n",
    "\n",
    "        print(record)\n",
    "\n",
    "        if record is None:\n",
    "            print(f\"WARNING: No record found for {chrom}:{pos}. Skipping.\")\n",
    "            continue\n",
    "        # Check if the record matches the chrom and pos\n",
    "        if record.CHROM == chrom and record.POS == pos:\n",
    "            chosen_records.append(record)\n",
    "\n",
    "    # 2b. Prepare a structure to hold the integer-coded genotype for each sample\n",
    "    sample2seq = {sample: [] for sample in samples}\n",
    "\n",
    "    # 2c. Fill sequence data (0,1,2,-)\n",
    "    for record in chosen_records:\n",
    "        genotypes = record.genotypes  # [ [g1, g2, phased, ...], [g1, g2, ...], ...]\n",
    "        for i, sample in enumerate(samples):\n",
    "\n",
    "            if sample in [\"waitaha\", \"richdalei\"]:\n",
    "                loc = [record.CHROM, record.POS]\n",
    "                if sample == \"waitaha\":\n",
    "                    gt_list = waitaha_sites.filter(\n",
    "                        (pl.col(\"chrom\") == loc[0]) & (pl.col(\"pos(1‑based)\") == loc[1])\n",
    "                    )['GT'].to_list()\n",
    "                else:  # sample == \"richdalei\"\n",
    "                    gt_list = richdalei_sites.filter(\n",
    "                        (pl.col(\"chrom\") == loc[0]) & (pl.col(\"pos(1‑based)\") == loc[1])\n",
    "                    )['GT'].to_list()\n",
    "                if gt_list:\n",
    "                    gt = gt_list[0]\n",
    "                    if gt == \"0/0\":\n",
    "                        code = \"0\"\n",
    "                    elif gt in [\"0/1\", \"1/0\"]:\n",
    "                        code = \"1\"\n",
    "                    elif gt == \"1/1\":\n",
    "                        code = \"2\"\n",
    "                    else:\n",
    "                        code = \"-\"\n",
    "                else:\n",
    "                    code = \"-\"\n",
    "            elif sample in vcf.samples:\n",
    "                g1, g2 = genotypes[i][0], genotypes[i][1]\n",
    "\n",
    "                # Missing genotype => '-'\n",
    "                if g1 < 0 or g2 < 0:\n",
    "                    code = '-'\n",
    "                else:\n",
    "                    # 0 = REF, 1 = ALT for each allele\n",
    "                    # Biallelic, so valid combos: (0,0), (0,1)/(1,0), (1,1)\n",
    "                    if g1 == 0 and g2 == 0:\n",
    "                        code = '0'\n",
    "                    elif (g1 == 0 and g2 == 1) or (g1 == 1 and g2 == 0):\n",
    "                        code = '1'\n",
    "                    elif g1 == 1 and g2 == 1:\n",
    "                        code = '2'\n",
    "                    else:\n",
    "                        # Shouldn't happen in a well-filtered biallelic VCF,\n",
    "                        # but just in case, treat as missing:\n",
    "                        code = '-'\n",
    "\n",
    "            sample2seq[sample].append(code)\n",
    "\n",
    "    # 2d. Write NEXUS for this replicate\n",
    "    out_nexus = f\"{output_prefix}_rep{rep_index}.nex\"\n",
    "    with open(out_nexus, \"w\") as out_f:\n",
    "        # Header\n",
    "        out_f.write(\"#NEXUS\\n\")\n",
    "        out_f.write(\"[SNP matrix in integer format: 0=homREF, 1=het, 2=homALT, -=missing]\\n\\n\")\n",
    "        out_f.write(\"Begin data;\\n\")\n",
    "        out_f.write(f\"\\tDimensions ntax={len(samples)} nchar={num_snps};\\n\")\n",
    "        out_f.write('\\tFormat datatype=integerdata symbols=\"012\" gap=-;\\n')\n",
    "        out_f.write(\"\\tMatrix\\n\")\n",
    "\n",
    "        # Matrix lines\n",
    "        for sample in samples:\n",
    "            seq_str = \"\".join(sample2seq[sample])\n",
    "            out_f.write(f\"{sample}\\t{seq_str}\\n\")\n",
    "\n",
    "        out_f.write(\"\\t;\\nEnd;\\n\")\n",
    "\n",
    "    print(f\"  -> Wrote replicate {rep_index} NEXUS: {out_nexus}\")\n",
    "\n",
    "print(\"All replicates done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep_index in range(1, num_replicates + 1):\n",
    "    print(f\"Generating replicate {rep_index} of {num_replicates} ...\")\n",
    "\n",
    "    # 2a. Randomly sample SNPs from possible sites (waitaha sites, since it has the least)\n",
    "    # chosen_records = random.sample(records, num_snps)\n",
    "    # Get indices of random sites, we can't use the sample function on Polars DataFrame directly\n",
    "    chosen_indices = random.sample(range(len(possible_sites)), num_snps)\n",
    "    chosen_sites = possible_sites[chosen_indices]\n",
    "    chosen_records = []\n",
    "    for site in chosen_sites.iter_rows(named=True):\n",
    "        chrom, pos = site['chrom'], site['pos(1‑based)']\n",
    "        # Find the record that matches this chrom and pos\n",
    "        record = vcf(f\"{chrom}:{pos}\")\n",
    "        # Record is now a generator, let's get the first one\n",
    "        record = next(record, None)  # Get the first record or None if not found\n",
    "\n",
    "        print(record)\n",
    "\n",
    "        if record is None:\n",
    "            print(f\"WARNING: No record found for {chrom}:{pos}. Skipping.\")\n",
    "            continue\n",
    "        # Check if the record matches the chrom and pos\n",
    "        if record.CHROM == chrom and record.POS == pos:\n",
    "            chosen_records.append(record)\n",
    "\n",
    "    # 2b. Prepare a structure to hold the integer-coded genotype for each sample\n",
    "    sample2seq = {sample: [] for sample in samples}\n",
    "\n",
    "    # 2c. Fill sequence data (0,1,2,-)\n",
    "    for record in chosen_records:\n",
    "        genotypes = record.genotypes  # [ [g1, g2, phased, ...], [g1, g2, ...], ...]\n",
    "        for i, sample in enumerate(samples):\n",
    "\n",
    "            if sample in [\"waitaha\", \"richdalei\"]:\n",
    "                loc = [record.CHROM, record.POS]\n",
    "                if sample == \"waitaha\":\n",
    "                    gt_list = waitaha_sites.filter(\n",
    "                        (pl.col(\"chrom\") == loc[0]) & (pl.col(\"pos(1‑based)\") == loc[1])\n",
    "                    )['GT'].to_list()\n",
    "                else:  # sample == \"richdalei\"\n",
    "                    gt_list = richdalei_sites.filter(\n",
    "                        (pl.col(\"chrom\") == loc[0]) & (pl.col(\"pos(1‑based)\") == loc[1])\n",
    "                    )['GT'].to_list()\n",
    "                if gt_list:\n",
    "                    gt = gt_list[0]\n",
    "                    if gt == \"0/0\":\n",
    "                        code = \"0\"\n",
    "                    elif gt in [\"0/1\", \"1/0\"]:\n",
    "                        code = \"1\"\n",
    "                    elif gt == \"1/1\":\n",
    "                        code = \"2\"\n",
    "                    else:\n",
    "                        code = \"-\"\n",
    "                else:\n",
    "                    code = \"-\"\n",
    "            elif sample in vcf.samples:\n",
    "                g1, g2 = genotypes[i][0], genotypes[i][1]\n",
    "\n",
    "                # Missing genotype => '-'\n",
    "                if g1 < 0 or g2 < 0:\n",
    "                    code = '-'\n",
    "                else:\n",
    "                    # 0 = REF, 1 = ALT for each allele\n",
    "                    # Biallelic, so valid combos: (0,0), (0,1)/(1,0), (1,1)\n",
    "                    if g1 == 0 and g2 == 0:\n",
    "                        code = '0'\n",
    "                    elif (g1 == 0 and g2 == 1) or (g1 == 1 and g2 == 0):\n",
    "                        code = '1'\n",
    "                    elif g1 == 1 and g2 == 1:\n",
    "                        code = '2'\n",
    "                    else:\n",
    "                        # Shouldn't happen in a well-filtered biallelic VCF,\n",
    "                        # but just in case, treat as missing:\n",
    "                        code = '-'\n",
    "\n",
    "            sample2seq[sample].append(code)\n",
    "\n",
    "    # 2d. Write NEXUS for this replicate\n",
    "    out_nexus = f\"{output_prefix}_rep{rep_index}.nex\"\n",
    "    with open(out_nexus, \"w\") as out_f:\n",
    "        # Header\n",
    "        out_f.write(\"#NEXUS\\n\")\n",
    "        out_f.write(\"[SNP matrix in integer format: 0=homREF, 1=het, 2=homALT, -=missing]\\n\\n\")\n",
    "        out_f.write(\"Begin data;\\n\")\n",
    "        out_f.write(f\"\\tDimensions ntax={len(samples)} nchar={num_snps};\\n\")\n",
    "        out_f.write('\\tFormat datatype=integerdata symbols=\"012\" gap=-;\\n')\n",
    "        out_f.write(\"\\tMatrix\\n\")\n",
    "\n",
    "        # Matrix lines\n",
    "        for sample in samples:\n",
    "            seq_str = \"\".join(sample2seq[sample])\n",
    "            out_f.write(f\"{sample}\\t{seq_str}\\n\")\n",
    "\n",
    "        out_f.write(\"\\t;\\nEnd;\\n\")\n",
    "\n",
    "    print(f\"  -> Wrote replicate {rep_index} NEXUS: {out_nexus}\")\n",
    "\n",
    "print(\"All replicates done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there's a SNP\n",
    "# halSnps --tsv snps --refSequence ptg000057l --start 63660 --length 100 /mnt/data/seabirds.hal a9 Eudyptesmoseleyi_genomic\n",
    "\n",
    "# If no SNP, see if it's a reference allele or missing sequence\n",
    "# halAlignmentDepth /mnt/data/seabirds.hal a9 --targetGenomes Eudyptesmoseleyi_genomic --refSequence ptg000057l --start 63660 --length 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do per contig\n",
    "for rep_index in range(1, num_replicates + 1):\n",
    "    print(f\"Generating replicate {rep_index} of {num_replicates} ...\")\n",
    "\n",
    "    # 2a. Randomly sample SNPs\n",
    "    chosen_records = random.sample(records, num_snps)\n",
    "\n",
    "    # 2b. Prepare a structure to hold the integer-coded genotype for each sample\n",
    "    # Per contig\n",
    "    sample2seq = {sample: [] for sample in samples}\n",
    "\n",
    "    # Sort the records by contig and position\n",
    "    chosen_records.sort(key=lambda r: (r.CHROM, r.start))\n",
    "\n",
    "    # Store the contig for each entry\n",
    "    contig2seq = {contig: [] for contig in set(r.CHROM for r in chosen_records)}\n",
    "    # Count the number of SNPs per contig\n",
    "    contig2num_snps = {contig: 0 for contig in contig2seq}\n",
    "\n",
    "    # 2c. Fill sequence data (0,1,2,-)\n",
    "    for record in chosen_records:\n",
    "        contig2num_snps[record.CHROM] += 1\n",
    "        genotypes = record.genotypes  # [ [g1, g2, phased, ...], [g1, g2, ...], ...]\n",
    "        for i, sample in enumerate(samples):\n",
    "            g1, g2 = genotypes[i][0], genotypes[i][1]\n",
    "\n",
    "            # Missing genotype => '-'\n",
    "            if g1 < 0 or g2 < 0:\n",
    "                code = '-'\n",
    "            else:\n",
    "                # 0 = REF, 1 = ALT for each allele\n",
    "                # Biallelic, so valid combos: (0,0), (0,1)/(1,0), (1,1)\n",
    "                if g1 == 0 and g2 == 0:\n",
    "                    code = '0'\n",
    "                elif (g1 == 0 and g2 == 1) or (g1 == 1 and g2 == 0):\n",
    "                    code = '1'\n",
    "                elif g1 == 1 and g2 == 1:\n",
    "                    code = '2'\n",
    "                else:\n",
    "                    # Shouldn't happen in a well-filtered biallelic VCF,\n",
    "                    # but just in case, treat as missing:\n",
    "                    code = '-'\n",
    "\n",
    "            sample2seq[sample].append(code)\n",
    "\n",
    "    # 2d. Write NEXUS for this replicate per contig\n",
    "\n",
    "    for contig, snpcount in contig2num_snps.items():\n",
    "        if snpcount == 0:\n",
    "            continue\n",
    "        out_nexus = f\"{output_prefix}_rep{rep_index}_{contig}.nex\"\n",
    "        \n",
    "        with open(out_nexus, \"w\") as out_f:\n",
    "            # Header\n",
    "            out_f.write(\"#NEXUS\\n\")\n",
    "            out_f.write(\"[SNP matrix in integer format: 0=homREF, 1=het, 2=homALT, -=missing]\\n\\n\")\n",
    "            out_f.write(\"Begin data;\\n\")\n",
    "            out_f.write(f\"\\tDimensions ntax={len(samples)} nchar={snpcount};\\n\")\n",
    "            out_f.write('\\tFormat datatype=integerdata symbols=\"012\" gap=-;\\n')\n",
    "            out_f.write(\"\\tMatrix\\n\")\n",
    "\n",
    "            # Matrix lines\n",
    "            for sample in samples:\n",
    "                seq_str = \"\".join(sample2seq[sample][:snpcount])\n",
    "                out_f.write(f\"{sample}\\t{seq_str}\\n\")\n",
    "\n",
    "                # Remove the first n snps from the list\n",
    "                sample2seq[sample] = sample2seq[sample][snpcount:]\n",
    "\n",
    "            out_f.write(\"\\t;\\nEnd;\\n\")\n",
    "\n",
    "        print(f\"  -> Wrote replicate {rep_index} NEXUS: {out_nexus}\")\n",
    "\n",
    "\n",
    "print(\"All replicates done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyvcf2 import VCF\n",
    "\n",
    "print(\"Generating SNP dataset from contig ptg000423c ...\")\n",
    "\n",
    "# Open BCF file and access the specific contig directly\n",
    "vcf = VCF(input_vcf)\n",
    "records = [record for record in vcf(\"ptg000423c\")]  # Random access to contig\n",
    "\n",
    "# Sort SNPs by position\n",
    "chosen_records = sorted(records, key=lambda r: r.POS)\n",
    "\n",
    "# Prepare a structure to hold the integer-coded genotype for each sample\n",
    "samples = vcf.samples\n",
    "sample2seq = {sample: [] for sample in samples}\n",
    "\n",
    "# Fill sequence data (0,1,2,-)\n",
    "for record in chosen_records:\n",
    "    genotypes = record.genotypes  # [ [g1, g2, phased, ...], [g1, g2, ...], ...]\n",
    "    for i, sample in enumerate(samples):\n",
    "        g1, g2 = genotypes[i][0], genotypes[i][1]\n",
    "\n",
    "        # Missing genotype => '-'\n",
    "        if g1 < 0 or g2 < 0:\n",
    "            code = '-'\n",
    "        else:\n",
    "            # 0 = REF, 1 = ALT for each allele\n",
    "            if g1 == 0 and g2 == 0:\n",
    "                code = '0'\n",
    "            elif (g1 == 0 and g2 == 1) or (g1 == 1 and g2 == 0):\n",
    "                code = '1'\n",
    "            elif g1 == 1 and g2 == 1:\n",
    "                code = '2'\n",
    "            else:\n",
    "                code = '-'\n",
    "\n",
    "        sample2seq[sample].append(code)\n",
    "\n",
    "# Write NEXUS file\n",
    "out_nexus = f\"{output_prefix}.nex\"\n",
    "with open(out_nexus, \"w\") as out_f:\n",
    "    # Header\n",
    "    out_f.write(\"#NEXUS\\n\")\n",
    "    out_f.write(\"[SNP matrix in integer format: 0=homREF, 1=het, 2=homALT, -=missing]\\n\\n\")\n",
    "    out_f.write(\"Begin data;\\n\")\n",
    "    out_f.write(f\"\\tDimensions ntax={len(samples)} nchar={len(chosen_records)};\\n\")\n",
    "    out_f.write('\\tFormat datatype=integerdata symbols=\"012\" gap=-;\\n')\n",
    "    out_f.write(\"\\tMatrix\\n\")\n",
    "\n",
    "    # Matrix lines\n",
    "    for sample in samples:\n",
    "        seq_str = \"\".join(sample2seq[sample])\n",
    "        out_f.write(f\"{sample}\\t{seq_str}\\n\")\n",
    "\n",
    "    out_f.write(\"\\t;\\nEnd;\\n\")\n",
    "\n",
    "print(f\"  -> Wrote NEXUS file: {out_nexus}\")\n",
    "print(\"All SNP data processing done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
